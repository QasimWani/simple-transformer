{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd545a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521c5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SimpleGPT, device\n",
    "from main import WikiTextDataset, get_wiki_dataloader, train, generate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e7607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qasim/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tr_ds = get_wiki_dataloader(subset_size=int(1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d97782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGPT().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2ba3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50/10000.0  loss 9.4730  lr 3.00e-05\n",
      "step 100/10000.0  loss 7.9342  lr 6.00e-05\n",
      "step 150/10000.0  loss 7.2708  lr 9.00e-05\n",
      "step 200/10000.0  loss 7.0581  lr 1.20e-04\n",
      "step 250/10000.0  loss 6.8566  lr 1.50e-04\n",
      "step 300/10000.0  loss 6.6939  lr 1.80e-04\n",
      "step 350/10000.0  loss 6.3011  lr 2.10e-04\n",
      "step 400/10000.0  loss 5.7038  lr 2.40e-04\n",
      "step 450/10000.0  loss 5.4322  lr 2.70e-04\n",
      "step 500/10000.0  loss 5.5764  lr 3.00e-04\n",
      "step 550/10000.0  loss 4.6769  lr 3.00e-04\n",
      "step 600/10000.0  loss 4.8745  lr 3.00e-04\n",
      "step 650/10000.0  loss 3.8260  lr 3.00e-04\n",
      "step 700/10000.0  loss 4.1957  lr 3.00e-04\n",
      "step 750/10000.0  loss 4.0231  lr 2.99e-04\n",
      "step 800/10000.0  loss 2.7749  lr 2.99e-04\n",
      "step 850/10000.0  loss 2.9228  lr 2.99e-04\n",
      "step 900/10000.0  loss 1.9282  lr 2.99e-04\n",
      "step 950/10000.0  loss 1.9336  lr 2.98e-04\n",
      "step 1000/10000.0  loss 2.2346  lr 2.98e-04\n",
      "step 1050/10000.0  loss 1.2447  lr 2.98e-04\n",
      "step 1100/10000.0  loss 1.1444  lr 2.97e-04\n",
      "step 1150/10000.0  loss 0.7042  lr 2.97e-04\n",
      "step 1200/10000.0  loss 0.6376  lr 2.96e-04\n",
      "step 1250/10000.0  loss 0.9174  lr 2.95e-04\n",
      "step 1300/10000.0  loss 0.3490  lr 2.95e-04\n",
      "step 1350/10000.0  loss 0.3874  lr 2.94e-04\n",
      "step 1400/10000.0  loss 0.2401  lr 2.93e-04\n",
      "step 1450/10000.0  loss 0.2843  lr 2.93e-04\n",
      "step 1500/10000.0  loss 0.2955  lr 2.92e-04\n",
      "step 1550/10000.0  loss 0.1694  lr 2.91e-04\n",
      "step 1600/10000.0  loss 0.1987  lr 2.90e-04\n",
      "step 1650/10000.0  loss 0.1396  lr 2.89e-04\n",
      "step 1700/10000.0  loss 0.1483  lr 2.88e-04\n",
      "step 1750/10000.0  loss 0.2249  lr 2.87e-04\n",
      "step 1800/10000.0  loss 0.1323  lr 2.86e-04\n",
      "step 1850/10000.0  loss 0.2080  lr 2.85e-04\n",
      "step 1900/10000.0  loss 0.1086  lr 2.84e-04\n",
      "step 1950/10000.0  loss 0.1167  lr 2.83e-04\n",
      "step 2000/10000.0  loss 0.1457  lr 2.82e-04\n",
      "step 2050/10000.0  loss 0.1248  lr 2.81e-04\n",
      "step 2100/10000.0  loss 0.1302  lr 2.79e-04\n",
      "step 2150/10000.0  loss 0.0836  lr 2.78e-04\n",
      "step 2200/10000.0  loss 0.0989  lr 2.77e-04\n",
      "step 2250/10000.0  loss 0.0835  lr 2.76e-04\n",
      "step 2300/10000.0  loss 0.1103  lr 2.74e-04\n",
      "step 2350/10000.0  loss 0.0914  lr 2.73e-04\n",
      "step 2400/10000.0  loss 0.0628  lr 2.71e-04\n",
      "step 2450/10000.0  loss 0.0940  lr 2.70e-04\n",
      "step 2500/10000.0  loss 0.1008  lr 2.68e-04\n",
      "step 2550/10000.0  loss 0.0699  lr 2.67e-04\n",
      "step 2600/10000.0  loss 0.0936  lr 2.65e-04\n",
      "step 2650/10000.0  loss 0.0649  lr 2.64e-04\n",
      "step 2700/10000.0  loss 0.1052  lr 2.62e-04\n",
      "step 2750/10000.0  loss 0.0815  lr 2.60e-04\n",
      "step 2800/10000.0  loss 0.0766  lr 2.59e-04\n",
      "step 2850/10000.0  loss 0.0918  lr 2.57e-04\n",
      "step 2900/10000.0  loss 0.0591  lr 2.55e-04\n",
      "step 2950/10000.0  loss 0.0939  lr 2.53e-04\n",
      "step 3000/10000.0  loss 0.0781  lr 2.52e-04\n",
      "step 3050/10000.0  loss 0.0800  lr 2.50e-04\n",
      "step 3100/10000.0  loss 0.0587  lr 2.48e-04\n",
      "step 3150/10000.0  loss 0.0797  lr 2.46e-04\n",
      "step 3200/10000.0  loss 0.0540  lr 2.44e-04\n",
      "step 3250/10000.0  loss 0.0712  lr 2.42e-04\n",
      "step 3300/10000.0  loss 0.0691  lr 2.40e-04\n",
      "step 3350/10000.0  loss 0.0684  lr 2.38e-04\n",
      "step 3400/10000.0  loss 0.0344  lr 2.36e-04\n",
      "step 3450/10000.0  loss 0.0657  lr 2.34e-04\n",
      "step 3500/10000.0  loss 0.0743  lr 2.32e-04\n",
      "step 3550/10000.0  loss 0.0480  lr 2.30e-04\n",
      "step 3600/10000.0  loss 0.0639  lr 2.28e-04\n",
      "step 3650/10000.0  loss 0.0454  lr 2.26e-04\n",
      "step 3700/10000.0  loss 0.0393  lr 2.24e-04\n",
      "step 3750/10000.0  loss 0.0864  lr 2.21e-04\n",
      "step 3800/10000.0  loss 0.0308  lr 2.19e-04\n",
      "step 3850/10000.0  loss 0.0534  lr 2.17e-04\n",
      "step 3900/10000.0  loss 0.0538  lr 2.15e-04\n",
      "step 3950/10000.0  loss 0.0662  lr 2.13e-04\n",
      "step 4000/10000.0  loss 0.0437  lr 2.10e-04\n",
      "step 4050/10000.0  loss 0.0727  lr 2.08e-04\n",
      "step 4100/10000.0  loss 0.0494  lr 2.06e-04\n",
      "step 4150/10000.0  loss 0.0325  lr 2.03e-04\n",
      "step 4200/10000.0  loss 0.0333  lr 2.01e-04\n",
      "step 4250/10000.0  loss 0.0674  lr 1.99e-04\n",
      "step 4300/10000.0  loss 0.0685  lr 1.96e-04\n",
      "step 4350/10000.0  loss 0.0375  lr 1.94e-04\n",
      "step 4400/10000.0  loss 0.0343  lr 1.92e-04\n",
      "step 4450/10000.0  loss 0.0573  lr 1.89e-04\n",
      "step 4500/10000.0  loss 0.0368  lr 1.87e-04\n",
      "step 4550/10000.0  loss 0.0488  lr 1.84e-04\n",
      "step 4600/10000.0  loss 0.0421  lr 1.82e-04\n",
      "step 4650/10000.0  loss 0.0277  lr 1.80e-04\n",
      "step 4700/10000.0  loss 0.0446  lr 1.77e-04\n",
      "step 4750/10000.0  loss 0.0495  lr 1.75e-04\n",
      "step 4800/10000.0  loss 0.1332  lr 1.72e-04\n",
      "step 4850/10000.0  loss 0.0506  lr 1.70e-04\n",
      "step 4900/10000.0  loss 0.0468  lr 1.67e-04\n",
      "step 4950/10000.0  loss 0.0347  lr 1.65e-04\n",
      "step 5000/10000.0  loss 0.0540  lr 1.62e-04\n",
      "step 5050/10000.0  loss 0.0336  lr 1.60e-04\n",
      "step 5100/10000.0  loss 0.0349  lr 1.57e-04\n",
      "step 5150/10000.0  loss 0.0360  lr 1.55e-04\n",
      "step 5200/10000.0  loss 0.0237  lr 1.52e-04\n",
      "step 5250/10000.0  loss 0.0352  lr 1.50e-04\n",
      "step 5300/10000.0  loss 0.0263  lr 1.48e-04\n",
      "step 5350/10000.0  loss 0.0473  lr 1.45e-04\n",
      "step 5400/10000.0  loss 0.0473  lr 1.43e-04\n",
      "step 5450/10000.0  loss 0.0250  lr 1.40e-04\n",
      "step 5500/10000.0  loss 0.0365  lr 1.38e-04\n",
      "step 5550/10000.0  loss 0.0304  lr 1.35e-04\n",
      "step 5600/10000.0  loss 0.0357  lr 1.33e-04\n",
      "step 5650/10000.0  loss 0.0283  lr 1.30e-04\n",
      "step 5700/10000.0  loss 0.0453  lr 1.28e-04\n",
      "step 5750/10000.0  loss 0.0463  lr 1.25e-04\n",
      "step 5800/10000.0  loss 0.0195  lr 1.23e-04\n",
      "step 5850/10000.0  loss 0.0395  lr 1.20e-04\n",
      "step 5900/10000.0  loss 0.0245  lr 1.18e-04\n",
      "step 5950/10000.0  loss 0.0213  lr 1.16e-04\n",
      "step 6000/10000.0  loss 0.0384  lr 1.13e-04\n",
      "step 6050/10000.0  loss 0.0190  lr 1.11e-04\n",
      "step 6100/10000.0  loss 0.0319  lr 1.08e-04\n",
      "step 6150/10000.0  loss 0.0332  lr 1.06e-04\n",
      "step 6200/10000.0  loss 0.0381  lr 1.04e-04\n",
      "step 6250/10000.0  loss 0.0209  lr 1.01e-04\n",
      "step 6300/10000.0  loss 0.0252  lr 9.90e-05\n",
      "step 6350/10000.0  loss 0.0408  lr 9.66e-05\n",
      "step 6400/10000.0  loss 0.0170  lr 9.43e-05\n",
      "step 6450/10000.0  loss 0.0341  lr 9.20e-05\n",
      "step 6500/10000.0  loss 0.0233  lr 8.97e-05\n",
      "step 6550/10000.0  loss 0.0366  lr 8.75e-05\n",
      "step 6600/10000.0  loss 0.0171  lr 8.52e-05\n",
      "step 6650/10000.0  loss 0.0313  lr 8.30e-05\n",
      "step 6700/10000.0  loss 0.0252  lr 8.08e-05\n",
      "step 6750/10000.0  loss 0.0202  lr 7.86e-05\n",
      "step 6800/10000.0  loss 0.0154  lr 7.64e-05\n",
      "step 6850/10000.0  loss 0.0264  lr 7.43e-05\n",
      "step 6900/10000.0  loss 0.0079  lr 7.22e-05\n",
      "step 6950/10000.0  loss 0.0235  lr 7.00e-05\n",
      "step 7000/10000.0  loss 0.0236  lr 6.80e-05\n",
      "step 7050/10000.0  loss 0.0322  lr 6.59e-05\n",
      "step 7100/10000.0  loss 0.0218  lr 6.39e-05\n",
      "step 7150/10000.0  loss 0.0201  lr 6.18e-05\n",
      "step 7200/10000.0  loss 0.0248  lr 5.98e-05\n",
      "step 7250/10000.0  loss 0.0188  lr 5.79e-05\n",
      "step 7300/10000.0  loss 0.0256  lr 5.59e-05\n",
      "step 7350/10000.0  loss 0.0214  lr 5.40e-05\n",
      "step 7400/10000.0  loss 0.0300  lr 5.21e-05\n",
      "step 7450/10000.0  loss 0.0299  lr 5.02e-05\n",
      "step 7500/10000.0  loss 0.0400  lr 4.84e-05\n",
      "step 7550/10000.0  loss 0.0227  lr 4.66e-05\n",
      "step 7600/10000.0  loss 0.0287  lr 4.48e-05\n",
      "step 7650/10000.0  loss 0.0316  lr 4.31e-05\n",
      "step 7700/10000.0  loss 0.0355  lr 4.13e-05\n",
      "step 7750/10000.0  loss 0.0291  lr 3.96e-05\n",
      "step 7800/10000.0  loss 0.0234  lr 3.80e-05\n",
      "step 7850/10000.0  loss 0.0266  lr 3.63e-05\n",
      "step 7900/10000.0  loss 0.0174  lr 3.47e-05\n",
      "step 7950/10000.0  loss 0.0267  lr 3.32e-05\n",
      "step 8000/10000.0  loss 0.0206  lr 3.16e-05\n",
      "step 8050/10000.0  loss 0.0225  lr 3.01e-05\n",
      "step 8100/10000.0  loss 0.0236  lr 2.86e-05\n",
      "step 8150/10000.0  loss 0.0211  lr 2.72e-05\n",
      "step 8200/10000.0  loss 0.0158  lr 2.58e-05\n",
      "step 8250/10000.0  loss 0.0293  lr 2.44e-05\n",
      "step 8300/10000.0  loss 0.0174  lr 2.31e-05\n",
      "step 8350/10000.0  loss 0.0184  lr 2.18e-05\n",
      "step 8400/10000.0  loss 0.0182  lr 2.05e-05\n",
      "step 8450/10000.0  loss 0.0116  lr 1.93e-05\n",
      "step 8500/10000.0  loss 0.0192  lr 1.81e-05\n",
      "step 8550/10000.0  loss 0.0161  lr 1.69e-05\n",
      "step 8600/10000.0  loss 0.0182  lr 1.58e-05\n",
      "step 8650/10000.0  loss 0.0352  lr 1.47e-05\n",
      "step 8700/10000.0  loss 0.0269  lr 1.36e-05\n",
      "step 8750/10000.0  loss 0.0127  lr 1.26e-05\n",
      "step 8800/10000.0  loss 0.0106  lr 1.17e-05\n",
      "step 8850/10000.0  loss 0.0170  lr 1.07e-05\n",
      "step 8900/10000.0  loss 0.0339  lr 9.82e-06\n",
      "step 8950/10000.0  loss 0.0124  lr 8.95e-06\n",
      "step 9000/10000.0  loss 0.0272  lr 8.13e-06\n",
      "step 9050/10000.0  loss 0.0171  lr 7.34e-06\n",
      "step 9100/10000.0  loss 0.0081  lr 6.59e-06\n",
      "step 9150/10000.0  loss 0.0093  lr 5.89e-06\n",
      "step 9200/10000.0  loss 0.0176  lr 5.22e-06\n",
      "step 9250/10000.0  loss 0.0224  lr 4.59e-06\n",
      "step 9300/10000.0  loss 0.0108  lr 4.00e-06\n",
      "step 9350/10000.0  loss 0.0218  lr 3.45e-06\n",
      "step 9400/10000.0  loss 0.0274  lr 2.94e-06\n",
      "step 9450/10000.0  loss 0.0158  lr 2.47e-06\n",
      "step 9500/10000.0  loss 0.0104  lr 2.05e-06\n",
      "step 9550/10000.0  loss 0.0230  lr 1.66e-06\n",
      "step 9600/10000.0  loss 0.0129  lr 1.31e-06\n",
      "step 9650/10000.0  loss 0.0145  lr 1.00e-06\n",
      "step 9700/10000.0  loss 0.0226  lr 7.38e-07\n",
      "step 9750/10000.0  loss 0.0214  lr 5.12e-07\n",
      "step 9800/10000.0  loss 0.0269  lr 3.28e-07\n",
      "step 9850/10000.0  loss 0.0124  lr 1.85e-07\n",
      "step 9900/10000.0  loss 0.0187  lr 8.20e-08\n",
      "step 9950/10000.0  loss 0.0125  lr 2.05e-08\n",
      "step 10000/10000.0  loss 0.0151  lr 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "model = train(tr_ds, max_steps=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6000cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book is about list of awards and nominations received by British actress Tilda Swinton. Throughout her career, Swinton has received several accolades, including one Academy Award, one BAFTA Award and a European Film Award, among others. Swinton began her career in several experimental films in the late 1980s. In 1991 she won the\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, tr_ds.dataset.tokenizer, \"This book is about\", temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
